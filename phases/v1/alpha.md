---
layout: default
title: Alpha
version: v1
redirect_from:
  - /phases/alpha.html
---

## User Needs

###  1

#### criteria
Understand user needs. Research to develop a deep knowledge of who the service users are and what that means for digital and assisted digital service design.

#### Prompts

* What user research has been completed during discovery and alpha? (should be more than just a one off survey)
* How many users did you speak to?
* Have you done qualitative and quantitative research?
* What have you learnt about your users that is specifically relevant to the design of the service?
* How has your research being applied to the design of the service?
* What are the user needs for your service? (Can you capture them in one sentence?)
* Have you created user stories based on user needs?
* Have you researched what the service should be called to best meet user needs?

#### Evidence

Service Manager able to:

* explain clearly what user research has been completed during discover and alpha
* explain the user research methods, frequency of testing (normally with at least 5 users for each sprint), types of recruits and where they were recruited from, resources available and communication process into the service team to inform the design
* explain what has been learnt about users and user needs, including population demographics and digital proficiency profiles
* give an example of a user story, the need it relates to and how that user need was determined

### 20

#### Criteria
Put a plan in place for ongoing user research and usability testing to continuously seek feedback from users.

#### Prompts

* What did you learn from user research and usability testing during the alpha?
* Are the resources in place to do regular user research and usability testing?
* Do you have a testing environment in place?
* Who in the team is doing user research and usability testing?
* How often are you doing user research and usability testing during the alpha?
* How do the results feed into the design of the service?
* What is the user research plan for the beta stage and are there resources for user research and usability testing?

#### Evidence

Service manager able to:

* explain what they learnt during the alpha and how this was incorporated into the service design
* explain who is doing user research and usability testing and how it is being resourced
* explain their testing environment
* explain how often they are doing user research and usability testing
* explain how the results from user research and usability testing are incorporated into the design of the service

## The Team

### 2

#### Criteria
Put in place a sustainable multidisciplinary team that can design, build and operate the service, led by a suitably skilled and senior service manager with decision-making responsibility.

#### Prompts

* Can you talk us through your team for the alpha?
* Is the service manager empowered to make decisions during the alpha?
* Do you have confirmation of this from above?
* Is the service manager the single responsible person with the power and knowledge to make decisions to improve the service day to day during the alpha?
* Are there any gaps in the team and how are you addressing these?
* Is there a separation of key roles?

#### Evidence

Service Manager able to:

* clearly explain the structure of the team for the alpha (the following should be either in the team or available to the team depending on the scale of the service - service manager, product manager, delivery manager, tech lead, assisted digital lead, designer, user researcher, developers, content designer, technical architect, web ops, product analyst)
* explain how they are empowered to make decisions during the alpha
* explain where they have gaps in the team and explain how they will address them
* show that there is a separation of key roles (i.e. the same person is not performing multiple roles within the service)
* there is at least one user researcher working at least 3 days per week

### 6

#### Criteria
Build the service using the agile, iterative and user-centred methods set out in the manual

#### Prompts

* Talk us through how you are working in an agile way?
* What tools and techniques are you using to enable this way of working?
* How are you reviewing and iterating your processes?
* How are you able to adapt your processes to be responsive and iterate?
* How are you communicating within the team?
* Can you give an example of how you have responded to user research and usability testing?

#### Evidence

Service Manager able to:

* clearly explain how the service is working in an agile way, using agile tools and techniques
* explain how the service has reviewed and iterated their processes to be responsive
* explain how the team are using agile tools and techniques to communicate within the team
* give an example of how the service has responded to user research and usability testing

## Security, Privacy, Tools and Standards

### 3

#### Criteria
Evaluate what user data and information the service will be providing or storing, and address the security level, legal responsibilities, and risks associated with the service (consulting with experts where appropriate)

#### Prompts

* Have you engaged with the right people?
* Has a SIRO (Senior Information Risk Owner) been assigned and who are they?
* Has a (IAO) Information Asset Owner been assigned?
* Has an Accreditor been assigned to the project?
* Have you set the risk appetite for the project?
* What are you worried about?
* Why is the architecture of the service the way it is?
* What is the relationship between the service manager and the SIRO?
* Have you done a risk assessment and who has signed off the risks?
* Is the level of security appropriate (i.e. not too high or too low)?
* Has the service been subject to an assessment using [Requirements for Secure Delivery of Online Public Services](https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/270969/GPG_43_RSDOPS_Annex_A__issue_1.1_Dec_2012.pdf) (RSDOPS)?
* What identity assurance needs were identified and how are they being met?

#### Evidence

Service Manager able to:

* show that the security of the service is owned by the team under the service manager and that there has been proportionate external validation
* explain who they have engaged with
* confirm who the SIRO, Information Asset Owner and Accreditor are for the project
* explain what the risk appetite is for the project
* explain the architecture of the service and why they have chosen it
* confirm they have done a risk assessment and explain who has signed off the risks
* explain the level of security of and why it was chosen
* confirm service assessed against RSDOPS to identify the risks and the extent to which the service needs to know that users are who they say they are
* identified if the service needs to use identity assurance and if so what type/level.

### 4

#### Criteria
Evaluate the privacy risks to make sure that personal data collection requirements are appropriate

#### Prompts

* What have you done to ensure compliance with the Data Protection Act?
* What data goes where and why?
* Who is the data controller for the service?
* How have you ensured you follow cookie policy?

#### Evidence

Service Manager able to:

* explain how the service complies with the Data Protection Act
* explain data flows i.e. what data goes where and why
* confirm who the data controller is for the service
* explain how the service complies with cookie policy

### 5

#### Criteria
Evaluate what tools and systems will be used to build, host, operate and measure a service, and how to procure them

#### Prompts

* How did you choose technology for the alpha?
* What tools are you using for the alpha?
* What options were considered and what factors led to the decision?
* How are you avoiding lock-in during the alpha and beyond?
* Are the contracts in place suitably flexible and delivering value for money?
* What procurement vehicles have you used and why?
* What changes are you planning to make?

#### Evidence

Service Manager able to:

* explain what technology and tools the service has bought, built and uses for the alpha and why they have chosen them
* explain how they are avoiding lock in, how their contracts are suitably flexible and how they are delivering value for money
* explain what procurement vehicles they have used and why
* explain what changes they are planning to make

### 15

#### Criteria
Make all new source code open and reuseable, and publish it under appropriate licences (or provide a convincing explanation as to why this cannot be done for specific subsets of the source code)

#### Prompts

* Talk us through your plan for making all new source code open and reusable?
* Do you own the intellectual property?
* Will I be able to reuse your code in another department?

#### Evidence

Service manager able to:

* explain their plan for making all new source code open and reusable during the alpha
* confirm that the service owns the intellectual property or give a valid explanation why not
* explain how other departments will be able to reuse their code during alpha

### 16

#### Criteria
Use open standards and common government platforms (eg identity assurance) where available

#### Prompts

* What open standards are you using?
* Are you complying with the open standards board's decisions?
* Are you imposing vendor technology choices on users?
* What standards are you using to reduce lock-in?
* Have you engaged with the identity assurance team in GDS?

#### Evidence

Service Manager able to:

* explain what open standards the service is using during the alpha
* explain how they are complying with the open standards board's decisions during the alpha
* explain how they are avoiding imposing vendor technology decisions on users and reducing lock-in during the alpha
* confirm that they have engaged with the identity assurance team in GDS

### 17

#### Criteria
Be able to test the end-to-end service in an environment identical to that of the live version on all common browsers and devices. Use dummy accounts and a representative sample of users.

#### Prompts

* How do you deploy in the alpha service and how do you test before deploying?
* Where do you do performance testing?
* Do you have an environment for previewing new features?
* Are you doing ongoing penetration testing?
* What browsers and devices do you support and why?

#### Evidence

Service Manager able to:

* explain how they deploy during the alpha and test before deploying
* explain how and where they do performance testing for the alpha service
* explain how they preview new features before deploying them to the alpha service
* explain their ongoing penetration testing during the alpha
* explain their browser and device testing during the alpha

### 25

#### Criteria
Make a plan for the event of the service being taken temporarily offline.

#### Prompts

* Do you have a disaster recovery plan?
* Have you evaluated your suppliers disaster recovery capability?
* Have you planned for the consequences of a forced shutdown in the alpha?
* Have you planned for a Distributed Denial of Service (DDoS) attack and other malicious attacks in the alpha?
* Have you done sufficient load testing for the alpha?
* Do you have a line into GovCertUK for reporting in the event of an incident?

#### Evidence

Service manager able to:

* explain their disaster recovery plan for the alpha, including understanding their suppliers disaster recovery capability where appropriate
* explain how the service would deal with a forced shutdown in the alpha
* explain how they will deal with a DDoS attack and other malicious attacks in the alpha
* explain what load testing they have done for the alpha
* confirm they are aware of GovCertUK and are aware of how to report an incident


## Improving the Service

### 14

#### Criteria
Make sure that you have the capacity and technical flexibility to update and improve the service on a very frequent basis

#### Prompts

* Talk us through your deployment process for the alpha?
* How long does it take to make a change to the service during the alpha?
* Who can make a change during the alpha?
* Who can authorise making a change during the alpha?
* How do you test a change before it is made during the alpha?
* Do you require downtime for a release during the alpha? How long is the downtime?

#### Evidence

Service Manager able to:

- clearly explain their deployment process for the alpha
- explain how long it takes to make a change to the service during the alpha
- explain who can make a change and who can authorise a change during the alpha
- explain how they test a change before it is made during the alpha
- explain why the service requires downtime for a release and how long that downtime is during the alpha

### 19

#### Criteria
Build a service that can be iterated on a frequent basis and make sure resources are in place to do so
#### Prompts

* How did you iterate the service frequently during the alpha?
* Who was responsible for user research, usability testing and identifying actionable data insights during the alpha?
#### Evidence

Service Manager able to:

- explain how they have iterated the service frequently during the alpha
- explain who was responsible for user research, usability testing and identifying actionable data insights during the alpha

## Design

### 9

#### Criteria
Create a service that is simple and intuitive enough that users succeed first time, unaided

#### Prompts

* How did you collect evidence that users of the alpha service are, in the majority of cases, succeeding first time?

#### Evidence

Service Manager able to:

- explain how they collected evidence that users of the alpha service are, in the majority of cases, succeeding first time
### 12

#### Criteria

Integrate the service with any non-digital sections required for legal reasons

#### Prompts

* Does the service have any non-digital steps during the alpha and if so, why?
* What has been done to ensure that any non-digital steps work seamlessly with the digital service?
* How have you tested the non-digital steps with users during the alpha?
* How are you planning to overcome any policy constraints and legislative barriers that are preventing the service from been an end to end digital service?

#### Evidence

Service Manager able to:

* explain why any non-digital steps are required for the alpha service
* how any non-digital steps seamlessly link to the digital service and how they have tested them with users during the alpha
* Identify any policy constraints or legislative barriers that are preventing the service from been an end to end digital service

### 13

#### Criteria

Build a service consistent with the user experience of the rest of GOV.UK by using the design patterns and style guide.

#### Prompts

Has a designer and content designer been involved during the alpha?
Have you used the GOV.UK design patterns and front end tool kit during alpha?
Do you have a front end developer in place?
Have you used the GDS style guide during the alpha?

#### Evidence

Service Manager able to:

* explain how the service will use the GOV.UK design patterns, front end tool kit and GDS style guide during the alpha
* explain what design, content design and front end developer support was available to the team during the alpha

## Assisted Digital and Channel Shift

### 10

#### Criteria


Put appropriate assisted digital support in place that’s aimed towards those who genuinely need it

#### Prompts

* What user research have you conducted with AD users and what have you learnt that will inform the design of your AD support?
* What are your plans to test, measure and iterate your AD support during beta?
* Will your AD support be sustainably funded and free to the user?
#### Evidence

Service Manager able to:

* Explain what types of research, when, with how many people, including recruitment specification
* Explain how the AD support might be tailored according to research carried out so far
* Explain why, if relevant, your service does not have to provide AD in line with GDS policy, and what alternative will be in place for any AD users
* Explain how you will test, measure and iterate your AD support during beta with AD users for the end-to-end user journey, including identity assurance
* Explain how you plan to ensure AD support is sustainably funded (including support not delivered by government) and free to the user

### 11

#### Criteria

Plan (with GDS) for the phasing out of any existing alternative channels, where appropriate

#### Prompts

* What is your plan for increasing digital take up?
* What other channels is the service currently delivered through?
* Do you collect data for these channels?
* What proportion of your users currently use your digital channel and complete the service in this way?
* What proportion of your users currently use and complete the transaction per channel?
* Which organisations/groups help your users with the existing digital or non-digital services?
* How has the digital service been designed to give it clear advantages over the other channels?

#### Evidence

Service Manager able to:

* explain their plan for increasing digital take up
* explain what other channels the service is delivered through
* explain what data they collect on their other channels
* analytical data on service usage for each channel
* A list of delivery 'providers' and the nature of the services they provide.
* Customer insight from: research with real users, user demographics, attitudes, behaviours and channel preferences and customer journey maps
* explain how each and every channels meet different users’ needs

## Analysis and Benchmarking

### 8

#### Criteria

Analyse the prototype service’s success, and translate user feedback into features and tasks for the next phase of development

#### Prompts

* What prototype testing did you do during the alpha?
* What did you plan to test?
* How did you test the prototype with end users?
* What did you learn?
* What did you change?
* What didn't you change and why?
* How many other versions of the prototype did you try?
* Why did you choose this version?

#### Evidence

Service Manager able to:

* talk clearly about user research reports, indicating where a service required remediation
* talk through substantial iteration in the design and content of the service during the alpha
* explain how prototype works as end to end user journey for all user needs, including those with AD needs

### 18

#### Criteria

Use analytics tools that collect performance data

#### Prompts

* What analytics tool have you installed for the alpha?
* Is your SIRO happy with it?
* Who does analytics in the team during the alpha?
* In addition to the 4 KPI's, what other KPI's are you tracking during the alpha?

#### Evidence

Service Manager able to:

* explain what analytics tool is installed for the alpha and that the SIRO is happy with this approach
* explain who in the team is responsible for identifying actionable data insights during the alpha
* explain what additional KPI's they are tracking during the alpha

### 7

#### Criteria

Establish performance benchmarks, in consultation with GDS, using the 4 key performance indicators (KPIs) defined in the manual, against which the service will be measured

#### Prompts

* Have you made contact with the performance platform?
* How are you measuring the performance of the old service to provide a baseline for the new service?

#### Evidence

Service Manager able to:

*  show they have made contact with the performance platform
*  explain how they currently measure the performance of the old service to provide a baseline for the new service

### 21
Establish a benchmark for user satisfaction across the digital and assisted digital service. Report performance data on the Performance Platform.

### 22
Establish a benchmark for completion rates across the digital and assisted digital service. Report performance data on the Performance Platform.

### 23
Make a plan (with supporting evidence) to achieve a low cost per transaction across the digital and assisted digital service. Report performance data on the Performance Platform.

### 24
Make a plan (with supporting evidence) to achieve a high digital take-up and assisted digital support for users who really need it. Report performance data on the Performance Platform."

#### Prompts

* Have you made contact with the performance platform?
* How are you measuring the performance of the old service to provide a baseline for the new service?
* Have you heard about stageprompt (or an equivalent event tracking)?
* Tell us about your plan to increase digital take up?
* How do current digital take up levels for your service compare with those of similar services?
* How are you measuring the performance of the service across all existing channels (This will provide a baseline for the new service)?

#### Evidence

Service Manager able to:

* show they have made contact with the performance platform and understand the role of stageprompt (or an equivalent event tracking) in getting their completion rate data on their performance dashboard
* explain how they currently measure the performance of the old service to provide a baseline for the new service
* explain their plan for increasing digital take-up
* explain how they measure the usage volumes for the current service(across channels) and explain how this information will be made available to Performance Platform team.
* explain how usage trends and insights drawn from similar services are informing their digital take-up plans

## Testing with the Minister

### 26

#### Criteria
Test the service from beginning to end with the minister responsible for it

#### Prompts

* How are you planning to test the service with the minister responsible for it before the service moves into Live?

#### Evidence

Service Manager able to:

* confirm the minister responsible for the service will test it before the service moves into Live